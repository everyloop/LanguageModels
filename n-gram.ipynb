{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea359af6",
   "metadata": {},
   "source": [
    "# N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf79430",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "NumberOfOutputSentences = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc500477",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f94fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = \"\"\"\n",
    "    A cat is an animal. \n",
    "    A dog is also an animal.\n",
    "    Both a cat and a dog are animals.\n",
    "    Every cat is an animal. \n",
    "    Every animal is not a cat. \n",
    "    A cat is never a dog.\n",
    "    The cat sat on the mat.\n",
    "    The dog barks at the cat.\n",
    "    The cat runs away.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7927b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alice.txt\", encoding=\"utf-8\") as file:\n",
    "    alice = file.read()\n",
    "\n",
    "with open(\"monteCristo.txt\", encoding=\"utf-8\") as file:\n",
    "    monteCristo = file.read()\n",
    "\n",
    "with open(\"cSharp.txt\", encoding=\"utf-8\") as file:\n",
    "    cSharp = file.read()\n",
    "\n",
    "trainingData = monteCristo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0951f3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedData = (\n",
    "    trainingData\n",
    "    .lower()\n",
    "    .replace(\".\", \" .\")\n",
    "    .split()\n",
    ")\n",
    "\n",
    "print(f\"{tokenizedData = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25381869",
   "metadata": {},
   "source": [
    "## Calculate token frequencies\n",
    "A.K.A counting the number of times each token occurs in the trainging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenFrequencies = {}\n",
    "\n",
    "for token in tokenizedData:\n",
    "    if token in tokenFrequencies:\n",
    "        tokenFrequencies[token] += 1\n",
    "    else:\n",
    "        tokenFrequencies[token] = 1\n",
    "\n",
    "print(f\"{tokenFrequencies = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb43f19",
   "metadata": {},
   "source": [
    "## Print probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eee9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, count in sorted(tokenFrequencies.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f'{token:15} {count / len(tokenizedData) * 100:-5,.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22884a24",
   "metadata": {},
   "source": [
    "## Unigram model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc283033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyPrint(words):\n",
    "    text = ''\n",
    "    isTitle = True\n",
    "\n",
    "    for word in words:\n",
    "        if word != '.' and text != '':\n",
    "            text += ' '\n",
    "\n",
    "        if isTitle:\n",
    "            text += word.capitalize()\n",
    "        else:\n",
    "            text += word\n",
    "\n",
    "        isTitle = (word == '.')\n",
    "    \n",
    "    print(text)\n",
    "\n",
    "words = []\n",
    "sentenceCounter = 0\n",
    "\n",
    "while (sentenceCounter < NumberOfOutputSentences):\n",
    "    currentWord = random.choices(list(tokenFrequencies.keys()), weights=tokenFrequencies.values())[0]\n",
    "    if currentWord == \".\": sentenceCounter += 1\n",
    "    words.append(currentWord)\n",
    "\n",
    "prettyPrint(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209ce21",
   "metadata": {},
   "source": [
    "## Building a bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3009f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for index in range(len(tokenizedData)-1):\n",
    "    currentWord = tokenizedData[index]\n",
    "    nextWord = tokenizedData[index + 1]\n",
    "\n",
    "    if not currentWord in bigrams:\n",
    "        bigrams[currentWord] = {nextWord: 1}\n",
    "    elif nextWord not in bigrams[currentWord]:\n",
    "        bigrams[currentWord][nextWord] = 1\n",
    "    else: \n",
    "        bigrams[currentWord][nextWord] += 1\n",
    "\n",
    "print(f\"{bigrams = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a66cd",
   "metadata": {},
   "source": [
    "## Print probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ngram_probabilities(ngrams):\n",
    "    BOLD = \"\\033[1m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    for head in sorted(ngrams.keys()):\n",
    "        print(f\"{BOLD}{head}{RESET}\")  # Huvudord\n",
    "\n",
    "        followers = ngrams[head]\n",
    "        total = sum(followers.values())  # Totalt antal följande ord\n",
    "        sorted_followers = sorted(followers.items())\n",
    "\n",
    "        for word, count in sorted_followers:\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    {word:<10} {percent:.2f}%\")  # Procent med två decimaler\n",
    "        print()\n",
    "\n",
    "print_ngram_probabilities(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53bc6b",
   "metadata": {},
   "source": [
    "## Bigram model output\n",
    "\n",
    "The following code generates a set number of sentences using a bigram model trained on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "sentenceCounter = 0\n",
    "\n",
    "while (sentenceCounter < NumberOfOutputSentences):\n",
    "    currentWord = words[-1] if len(words) > 0 else '.'\n",
    "\n",
    "    if currentWord not in bigrams: break\n",
    "    \n",
    "    currentWord = random.choices(list(bigrams[currentWord].keys()), weights=bigrams[currentWord].values())[0]\n",
    "    if currentWord == \".\": sentenceCounter += 1\n",
    "\n",
    "    words.append(currentWord)\n",
    "\n",
    "prettyPrint(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23862348",
   "metadata": {},
   "source": [
    "# Generic code for n-Gram models\n",
    "The following below can be reused for n-gram models with different values of n.\n",
    "\n",
    "The output below shows a trigram data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(n):\n",
    "    ngrams = {}\n",
    "\n",
    "    for i in range(len(tokenizedData) - n + 1):\n",
    "        key = tuple(tokenizedData[i:i+n-1])\n",
    "        nextWord = tokenizedData[i+n-1]\n",
    "\n",
    "        if not key in ngrams:\n",
    "            ngrams[key] = {nextWord: 1}\n",
    "        elif nextWord not in ngrams[key]:\n",
    "            ngrams[key][nextWord] = 1\n",
    "        else:\n",
    "            ngrams[key][nextWord] += 1\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "ngrams = generate_ngrams(3)\n",
    "print(f\"{ngrams = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c48ba",
   "metadata": {},
   "source": [
    "## Print probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ngram_probabilities(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ff6a9",
   "metadata": {},
   "source": [
    "## Compare outputs for different n-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(ngrams):\n",
    "    contextLength = len(next(iter(ngrams)))\n",
    "    title = ['Unigram', 'Bigram', 'Trigram', 'Four-gram', 'Five-gram']\n",
    "\n",
    "    BOLD = \"\\033[1m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "    if contextLength < len(title):\n",
    "        print(f'{BOLD}{title[contextLength]}{RESET}')\n",
    "    else:\n",
    "        print(f'{BOLD}{contextLength + 1}-gram{RESET}')\n",
    "\n",
    "    startKeys = [key for key in ngrams.keys() if key[0] == '.']\n",
    "    words = list(random.choice(startKeys))\n",
    "    sentenceCounter = 0\n",
    "\n",
    "    while (sentenceCounter < NumberOfOutputSentences):\n",
    "        previousWords = tuple(words[-contextLength:])\n",
    "\n",
    "        if previousWords not in ngrams: break\n",
    "        \n",
    "        currentWord = random.choices(list(ngrams[previousWords].keys()), weights=ngrams[previousWords].values())[0]\n",
    "        if currentWord == \".\": sentenceCounter += 1\n",
    "\n",
    "        words.append(currentWord)\n",
    "\n",
    "    words = words[1:]\n",
    "\n",
    "    prettyPrint(words)\n",
    "    print()\n",
    "\n",
    "bigrams = generate_ngrams(2)\n",
    "trigrams = generate_ngrams(3)\n",
    "fourgrams = generate_ngrams(4)\n",
    "fivegrams = generate_ngrams(5)\n",
    "\n",
    "generate_text(bigrams)\n",
    "generate_text(trigrams)\n",
    "generate_text(fourgrams)\n",
    "generate_text(fivegrams)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanguageModels-n3fzzXD0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
