{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea359af6",
   "metadata": {},
   "source": [
    "# N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf79430",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2076ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "NumberOfOutputSentences = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc500477",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3f94fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = \"\"\"\n",
    "    A cat is an animal. \n",
    "    A dog is also an animal.\n",
    "    Both a cat and a dog are animals.\n",
    "    Every cat is an animal. \n",
    "    Every animal is not a cat. \n",
    "    A cat is never a dog.\n",
    "    The cat sat on the mat.\n",
    "    The dog barks at the cat.\n",
    "    The cat runs away.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0951f3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1e8f25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizedData = ['a', 'cat', 'is', 'an', 'animal', '.', 'a', 'dog', 'is', 'also', 'an', 'animal', '.', 'both', 'a', 'cat', 'and', 'a', 'dog', 'are', 'animals', '.', 'every', 'cat', 'is', 'an', 'animal', '.', 'every', 'animal', 'is', 'not', 'a', 'cat', '.', 'a', 'cat', 'is', 'never', 'a', 'dog', '.', 'the', 'cat', 'sat', 'on', 'the', 'mat', '.', 'the', 'dog', 'barks', 'at', 'the', 'cat', '.', 'the', 'cat', 'runs', 'away', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizedData = (\n",
    "    trainingData\n",
    "    .lower()\n",
    "    .replace(\".\", \" .\")\n",
    "    .split()\n",
    ")\n",
    "\n",
    "print(f\"{tokenizedData = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25381869",
   "metadata": {},
   "source": [
    "## Calculate token frequencies\n",
    "A.K.A counting the number of times each token occurs in the trainging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "09e8b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenFrequencies = {'a': 7, 'cat': 8, 'is': 5, 'an': 3, 'animal': 4, '.': 9, 'dog': 4, 'also': 1, 'both': 1, 'and': 1, 'are': 1, 'animals': 1, 'every': 2, 'not': 1, 'never': 1, 'the': 5, 'sat': 1, 'on': 1, 'mat': 1, 'barks': 1, 'at': 1, 'runs': 1, 'away': 1}\n"
     ]
    }
   ],
   "source": [
    "tokenFrequencies = {}\n",
    "\n",
    "for token in tokenizedData:\n",
    "    if token in tokenFrequencies:\n",
    "        tokenFrequencies[token] += 1\n",
    "    else:\n",
    "        tokenFrequencies[token] = 1\n",
    "\n",
    "print(f\"{tokenFrequencies = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb43f19",
   "metadata": {},
   "source": [
    "## Print probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "80eee9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".               14.75 %\n",
      "cat             13.11 %\n",
      "a               11.48 %\n",
      "is               8.20 %\n",
      "the              8.20 %\n",
      "animal           6.56 %\n",
      "dog              6.56 %\n",
      "an               4.92 %\n",
      "every            3.28 %\n",
      "also             1.64 %\n",
      "both             1.64 %\n",
      "and              1.64 %\n",
      "are              1.64 %\n",
      "animals          1.64 %\n",
      "not              1.64 %\n",
      "never            1.64 %\n",
      "sat              1.64 %\n",
      "on               1.64 %\n",
      "mat              1.64 %\n",
      "barks            1.64 %\n",
      "at               1.64 %\n",
      "runs             1.64 %\n",
      "away             1.64 %\n"
     ]
    }
   ],
   "source": [
    "for token, count in sorted(tokenFrequencies.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f'{token:15} {count / len(tokenizedData) * 100:-5,.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22884a24",
   "metadata": {},
   "source": [
    "## Unigram model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cc283033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Away animal never. Barks animal.. Cat an the is an every animal an the animal. A an both the.\n"
     ]
    }
   ],
   "source": [
    "def prettyPrint(words):\n",
    "    text = ''\n",
    "    isTitle = True\n",
    "\n",
    "    for word in words:\n",
    "        if word != '.' and text != '':\n",
    "            text += ' '\n",
    "\n",
    "        if isTitle:\n",
    "            text += word.capitalize()\n",
    "        else:\n",
    "            text += word\n",
    "\n",
    "        isTitle = (word == '.')\n",
    "    \n",
    "    print(text)\n",
    "\n",
    "words = []\n",
    "sentenceCounter = 0\n",
    "\n",
    "while (sentenceCounter < NumberOfOutputSentences):\n",
    "    currentWord = random.choices(list(tokenFrequencies.keys()), weights=tokenFrequencies.values())[0]\n",
    "    if currentWord == \".\": sentenceCounter += 1\n",
    "    words.append(currentWord)\n",
    "\n",
    "prettyPrint(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209ce21",
   "metadata": {},
   "source": [
    "## Building a bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dc3009f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams = {'a': {'cat': 4, 'dog': 3}, 'cat': {'is': 3, 'and': 1, '.': 2, 'sat': 1, 'runs': 1}, 'is': {'an': 2, 'also': 1, 'not': 1, 'never': 1}, 'an': {'animal': 3}, 'animal': {'.': 3, 'is': 1}, '.': {'a': 2, 'both': 1, 'every': 2, 'the': 3}, 'dog': {'is': 1, 'are': 1, '.': 1, 'barks': 1}, 'also': {'an': 1}, 'both': {'a': 1}, 'and': {'a': 1}, 'are': {'animals': 1}, 'animals': {'.': 1}, 'every': {'cat': 1, 'animal': 1}, 'not': {'a': 1}, 'never': {'a': 1}, 'the': {'cat': 3, 'mat': 1, 'dog': 1}, 'sat': {'on': 1}, 'on': {'the': 1}, 'mat': {'.': 1}, 'barks': {'at': 1}, 'at': {'the': 1}, 'runs': {'away': 1}, 'away': {'.': 1}}\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for index in range(len(tokenizedData)-1):\n",
    "    currentWord = tokenizedData[index]\n",
    "    nextWord = tokenizedData[index + 1]\n",
    "\n",
    "    if not currentWord in bigrams:\n",
    "        bigrams[currentWord] = {nextWord: 1}\n",
    "    elif nextWord not in bigrams[currentWord]:\n",
    "        bigrams[currentWord][nextWord] = 1\n",
    "    else: \n",
    "        bigrams[currentWord][nextWord] += 1\n",
    "\n",
    "print(f\"{bigrams = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a66cd",
   "metadata": {},
   "source": [
    "## Print probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "500f1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m.\u001b[0m\n",
      "    a          25.00%\n",
      "    both       12.50%\n",
      "    every      25.00%\n",
      "    the        37.50%\n",
      "\n",
      "\u001b[1ma\u001b[0m\n",
      "    cat        57.14%\n",
      "    dog        42.86%\n",
      "\n",
      "\u001b[1malso\u001b[0m\n",
      "    an         100.00%\n",
      "\n",
      "\u001b[1man\u001b[0m\n",
      "    animal     100.00%\n",
      "\n",
      "\u001b[1mand\u001b[0m\n",
      "    a          100.00%\n",
      "\n",
      "\u001b[1manimal\u001b[0m\n",
      "    .          75.00%\n",
      "    is         25.00%\n",
      "\n",
      "\u001b[1manimals\u001b[0m\n",
      "    .          100.00%\n",
      "\n",
      "\u001b[1mare\u001b[0m\n",
      "    animals    100.00%\n",
      "\n",
      "\u001b[1mat\u001b[0m\n",
      "    the        100.00%\n",
      "\n",
      "\u001b[1maway\u001b[0m\n",
      "    .          100.00%\n",
      "\n",
      "\u001b[1mbarks\u001b[0m\n",
      "    at         100.00%\n",
      "\n",
      "\u001b[1mboth\u001b[0m\n",
      "    a          100.00%\n",
      "\n",
      "\u001b[1mcat\u001b[0m\n",
      "    .          25.00%\n",
      "    and        12.50%\n",
      "    is         37.50%\n",
      "    runs       12.50%\n",
      "    sat        12.50%\n",
      "\n",
      "\u001b[1mdog\u001b[0m\n",
      "    .          25.00%\n",
      "    are        25.00%\n",
      "    barks      25.00%\n",
      "    is         25.00%\n",
      "\n",
      "\u001b[1mevery\u001b[0m\n",
      "    animal     50.00%\n",
      "    cat        50.00%\n",
      "\n",
      "\u001b[1mis\u001b[0m\n",
      "    also       20.00%\n",
      "    an         40.00%\n",
      "    never      20.00%\n",
      "    not        20.00%\n",
      "\n",
      "\u001b[1mmat\u001b[0m\n",
      "    .          100.00%\n",
      "\n",
      "\u001b[1mnever\u001b[0m\n",
      "    a          100.00%\n",
      "\n",
      "\u001b[1mnot\u001b[0m\n",
      "    a          100.00%\n",
      "\n",
      "\u001b[1mon\u001b[0m\n",
      "    the        100.00%\n",
      "\n",
      "\u001b[1mruns\u001b[0m\n",
      "    away       100.00%\n",
      "\n",
      "\u001b[1msat\u001b[0m\n",
      "    on         100.00%\n",
      "\n",
      "\u001b[1mthe\u001b[0m\n",
      "    cat        60.00%\n",
      "    dog        20.00%\n",
      "    mat        20.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOLD = \"\\033[1m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "for head in sorted(bigrams.keys()):\n",
    "    print(f\"{BOLD}{head}{RESET}\")  # Huvudord\n",
    "\n",
    "    followers = bigrams[head]\n",
    "    total = sum(followers.values())  # Totalt antal följande ord\n",
    "    sorted_followers = sorted(followers.items())\n",
    "\n",
    "    for word, count in sorted_followers:\n",
    "        percent = (count / total) * 100\n",
    "        print(f\"    {word:<10} {percent:.2f}%\")  # Procent med två decimaler\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53bc6b",
   "metadata": {},
   "source": [
    "## Bigram model output\n",
    "\n",
    "The following code generates a set number of sentences using a bigram model trained on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4a39dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every cat runs away. The cat sat on the cat is never a dog. A dog are animals. Both a dog barks at the mat. A dog.\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "sentenceCounter = 0\n",
    "\n",
    "while (sentenceCounter < NumberOfOutputSentences):\n",
    "    currentWord = words[-1] if len(words) > 0 else '.'\n",
    "\n",
    "    if currentWord not in bigrams: break\n",
    "    \n",
    "    currentWord = random.choices(list(bigrams[currentWord].keys()), weights=bigrams[currentWord].values())[0]\n",
    "    if currentWord == \".\": sentenceCounter += 1\n",
    "\n",
    "    words.append(currentWord)\n",
    "\n",
    "prettyPrint(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f19be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanguageModels-n3fzzXD0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
